{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "collapsed_sections": [
        "DcZG9rm2IAiA",
        "OLkInsdjyHMx",
        "F-LT4lCSxhe6",
        "770eDeeW9y8s",
        "GhBgkmGp44h1",
        "drSwyz5ees6u"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3eb7fd53f384a2587ea7755da289253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0538ce40cd684b939f83a2f8b5e3993e",
              "IPY_MODEL_20c3023552b746a8af3ad81987dade56",
              "IPY_MODEL_b4af7a24c17a4d83b9e4ef2c01a8abf1"
            ],
            "layout": "IPY_MODEL_0781de95c7f64eb18dfa48dbea8b600e"
          }
        },
        "0538ce40cd684b939f83a2f8b5e3993e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed40fd95fdf4f878f312329ddde61f4",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0532f90f9f4860860008fa7036aa6b",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "20c3023552b746a8af3ad81987dade56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3996e397a3d489ba3e53e0d4f593c5f",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14fbcc771517435893d7749cad4791ae",
            "value": 665
          }
        },
        "b4af7a24c17a4d83b9e4ef2c01a8abf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39607a5cc2104064bfd6b19600b1dd50",
            "placeholder": "​",
            "style": "IPY_MODEL_4aa1d5b0a6e34bfaa5dd9a7e6467ed64",
            "value": " 665/665 [00:00&lt;00:00, 58.2kB/s]"
          }
        },
        "0781de95c7f64eb18dfa48dbea8b600e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed40fd95fdf4f878f312329ddde61f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0532f90f9f4860860008fa7036aa6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3996e397a3d489ba3e53e0d4f593c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14fbcc771517435893d7749cad4791ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39607a5cc2104064bfd6b19600b1dd50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aa1d5b0a6e34bfaa5dd9a7e6467ed64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "252993fdf40c4255a0ca90987bbfa160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_477dfa9f147744e28d877524cf69c3db",
              "IPY_MODEL_a6dddadc99894d42ad6f28a96e0af143",
              "IPY_MODEL_765260d6b3c84d559120afbcd3a231f8"
            ],
            "layout": "IPY_MODEL_2c5bd7832a1f442f873dc699197b472c"
          }
        },
        "477dfa9f147744e28d877524cf69c3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1982310a15b44f2a8cb19a55e5eec543",
            "placeholder": "​",
            "style": "IPY_MODEL_cd4d16cdfa67428e8444af865b385c43",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "a6dddadc99894d42ad6f28a96e0af143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51ca627f7c4d49a6b7d151044647002f",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_027d093e5aae46f3ac3b7c0c127ec260",
            "value": 548105171
          }
        },
        "765260d6b3c84d559120afbcd3a231f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28c083bf4fbb47dbb0698ff9ded0dfe5",
            "placeholder": "​",
            "style": "IPY_MODEL_ebfd226f086547e6b0acaf5609a63b48",
            "value": " 548M/548M [00:02&lt;00:00, 188MB/s]"
          }
        },
        "2c5bd7832a1f442f873dc699197b472c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1982310a15b44f2a8cb19a55e5eec543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd4d16cdfa67428e8444af865b385c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51ca627f7c4d49a6b7d151044647002f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "027d093e5aae46f3ac3b7c0c127ec260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28c083bf4fbb47dbb0698ff9ded0dfe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebfd226f086547e6b0acaf5609a63b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "264f3f5ce88a49599344839005a2dc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5873c9d894194d95b05d424380f5589f",
              "IPY_MODEL_4238a5d20ea74ba7b99e7311c5471ffe",
              "IPY_MODEL_290d252476224cd8bc8ad93696f5e275"
            ],
            "layout": "IPY_MODEL_cc2cc3718c8e45a9bc90d9216990f2df"
          }
        },
        "5873c9d894194d95b05d424380f5589f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8666f8fbc3748b99000bd36e9e72af8",
            "placeholder": "​",
            "style": "IPY_MODEL_d4afc56257de4eb381e44be627152675",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "4238a5d20ea74ba7b99e7311c5471ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e91590bc144243e08110fb0f9a04b991",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b86d7793eda415fbcbde60ade461895",
            "value": 124
          }
        },
        "290d252476224cd8bc8ad93696f5e275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ab9232c1675462f97e91d46a243b344",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4b184f84bc40bbab894e1fbd4020f1",
            "value": " 124/124 [00:00&lt;00:00, 7.32kB/s]"
          }
        },
        "cc2cc3718c8e45a9bc90d9216990f2df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8666f8fbc3748b99000bd36e9e72af8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4afc56257de4eb381e44be627152675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e91590bc144243e08110fb0f9a04b991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b86d7793eda415fbcbde60ade461895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ab9232c1675462f97e91d46a243b344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4b184f84bc40bbab894e1fbd4020f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a8de3dd0af46048559590cabfe7e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4a84f43ed564415a5fffc2335598050",
              "IPY_MODEL_95bc1345418946d2899e12d04d49ebee",
              "IPY_MODEL_b3687fc275c14e998124758a0a273dd9"
            ],
            "layout": "IPY_MODEL_a0678325b2844d61b63dfe0cbe15b9b5"
          }
        },
        "f4a84f43ed564415a5fffc2335598050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeb503a0cd964b2997c4b7c3fe337629",
            "placeholder": "​",
            "style": "IPY_MODEL_04aa2678d05841018473814a74d39f16",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "95bc1345418946d2899e12d04d49ebee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d4048c18906493c9cacefbd99489dee",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30df5cb87b34488fba9d720327ee73d1",
            "value": 1042301
          }
        },
        "b3687fc275c14e998124758a0a273dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a11a28b9c821482abfa9b96a8694946e",
            "placeholder": "​",
            "style": "IPY_MODEL_90cab21801db4305a275d4ebe50fca7c",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.59MB/s]"
          }
        },
        "a0678325b2844d61b63dfe0cbe15b9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb503a0cd964b2997c4b7c3fe337629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04aa2678d05841018473814a74d39f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d4048c18906493c9cacefbd99489dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30df5cb87b34488fba9d720327ee73d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a11a28b9c821482abfa9b96a8694946e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90cab21801db4305a275d4ebe50fca7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "405a54edf77248efae0c7e8cea7dfca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab5c8a7ebc1e4cad8f7aa2ebef791bcd",
              "IPY_MODEL_e3c152a1f19e4094abc1e8f5d1458c5f",
              "IPY_MODEL_f2d14c98825c4613a2aa932e7b0036b4"
            ],
            "layout": "IPY_MODEL_5de38ea9f6c240f7a1179da0a7b2c7fe"
          }
        },
        "ab5c8a7ebc1e4cad8f7aa2ebef791bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfefc14764c74e64b3461ccbd7801dde",
            "placeholder": "​",
            "style": "IPY_MODEL_daf940fabcdb4651bc65e11760edf426",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "e3c152a1f19e4094abc1e8f5d1458c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2387707564ed41f3b42a2d3bfaa0baf6",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32ad23adcf414df08d69729367d33558",
            "value": 456318
          }
        },
        "f2d14c98825c4613a2aa932e7b0036b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9188cb599b9948c2a88703f36f2c9e51",
            "placeholder": "​",
            "style": "IPY_MODEL_63bfc571db7043febd8a83536b68fd1f",
            "value": " 456k/456k [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "5de38ea9f6c240f7a1179da0a7b2c7fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfefc14764c74e64b3461ccbd7801dde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daf940fabcdb4651bc65e11760edf426": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2387707564ed41f3b42a2d3bfaa0baf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ad23adcf414df08d69729367d33558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9188cb599b9948c2a88703f36f2c9e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63bfc571db7043febd8a83536b68fd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a200035bed704d3f8ff74be5f019ce88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1abd8257caf84aefb9414dfb829d835a",
              "IPY_MODEL_f13483f3dd4d49ba87041efa3c53c46c",
              "IPY_MODEL_318b8032ca394b0fb41ff8fe7f43de97"
            ],
            "layout": "IPY_MODEL_75b3e5b0dcac4eda97037aa9fc822924"
          }
        },
        "1abd8257caf84aefb9414dfb829d835a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_211356e903ab4f85b03baacffc8549dd",
            "placeholder": "​",
            "style": "IPY_MODEL_a631271f51b844c89ba8382be197ebea",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "f13483f3dd4d49ba87041efa3c53c46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c17ec1ecc214f34b6f82b06db57f004",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_819e1bccf39a458a8fce7e3225748171",
            "value": 1355256
          }
        },
        "318b8032ca394b0fb41ff8fe7f43de97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27f3a407e6e647eb821294f00ccdaf9a",
            "placeholder": "​",
            "style": "IPY_MODEL_ffbfec6608834bd587cd0dfa961e06f7",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.4MB/s]"
          }
        },
        "75b3e5b0dcac4eda97037aa9fc822924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211356e903ab4f85b03baacffc8549dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a631271f51b844c89ba8382be197ebea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c17ec1ecc214f34b6f82b06db57f004": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819e1bccf39a458a8fce7e3225748171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27f3a407e6e647eb821294f00ccdaf9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffbfec6608834bd587cd0dfa961e06f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b13177b7"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlg100/numseqcont_circuit_expms/blob/main/notebook_templates/minimal_circuit_template.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" align=\"left\"/></a>&nbsp;or in a local notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcZG9rm2IAiA"
      },
      "source": [
        "# Setup\n",
        "(No need to change anything)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMcpSDdjIAiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f075b42d-1dad-4e14-a0aa-52e62925d70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
            "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-fho3vksd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-fho3vksd\n",
            "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit e9bbd6a95058ab0b5d6ba44223ee05564384f2ce\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens==0.0.0)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.7.1 (from transformer-lens==0.0.0)\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.0 (from transformer-lens==0.0.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer-lens==0.0.0)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer-lens==0.0.0)\n",
            "  Downloading jaxtyping-0.2.22-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (1.5.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (13.5.2)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer-lens==0.0.0) (4.66.1)\n",
            "Collecting transformers>=4.25.1 (from transformer-lens==0.0.0)\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb>=0.13.5 (from transformer-lens==0.0.0)\n",
            "  Downloading wandb-0.15.11-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.31.0)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets>=2.7.1->transformer-lens==0.0.0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (6.0.1)\n",
            "Collecting typeguard>=2.13.3 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n",
            "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2023.3.post1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer-lens==0.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->transformer-lens==0.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.25.1->transformer-lens==0.0.0)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2023.7.22)\n",
            "Collecting typing-extensions>=3.7.4.1 (from jaxtyping>=0.2.11->transformer-lens==0.0.0)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer-lens==0.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: transformer-lens, pathtools\n",
            "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=110239 sha256=f951eab6f45540d4872b5d08def2a2a3e28647bd7e138bc84dc4387997ef8852\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ckhdkbo0/wheels/8a/1e/37/ffb9c15454a1725b13a9d9f5e74fb91725048884ad734b8c1f\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=c133af5e66352d1a09075eb4cb322c933fa5575d8456b58cfce53d43a1911844\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built transformer-lens pathtools\n",
            "Installing collected packages: tokenizers, safetensors, pathtools, xxhash, typing-extensions, smmap, setproctitle, sentry-sdk, fancy-einsum, einops, docker-pycreds, dill, beartype, typeguard, multiprocess, huggingface-hub, gitdb, transformers, jaxtyping, GitPython, wandb, datasets, transformer-lens\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.37 beartype-0.14.1 datasets-2.14.5 dill-0.3.7 docker-pycreds-0.4.0 einops-0.7.0 fancy-einsum-0.0.3 gitdb-4.0.10 huggingface-hub-0.17.3 jaxtyping-0.2.22 multiprocess-0.70.15 pathtools-0.1.2 safetensors-0.3.3 sentry-sdk-1.31.0 setproctitle-1.3.2 smmap-5.0.1 tokenizers-0.13.3 transformer-lens-0.0.0 transformers-4.33.3 typeguard-4.1.5 typing-extensions-4.8.0 wandb-0.15.11 xxhash-3.3.0\n",
            "\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "  \u001b[1m\u001b[33m                         \u001b[4mSCRIPT DEPRECATION WARNING\u001b[m                    \u001b[m\n",
            "\n",
            "  \n",
            "  This script, located at \u001b[1mhttps://deb.nodesource.com/setup_X\u001b[m, used to\n",
            "  install Node.js is deprecated now and will eventually be made inactive.\n",
            "\n",
            "  Please visit the NodeSource \u001b[1mdistributions\u001b[m Github and follow the\n",
            "  instructions to migrate your repo.\n",
            "  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "  The \u001b[1mNodeSource\u001b[m Node.js Linux distributions GitHub repository contains\n",
            "  information about which versions of Node.js and which Linux distributions\n",
            "  are supported and how to install it.\n",
            "  \u001b[4m\u001b[32m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "\n",
            "                          \u001b[4m\u001b[1m\u001b[33mSCRIPT DEPRECATION WARNING\u001b[m\n",
            "\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\u001b[1m\u001b[31m▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓\u001b[m\n",
            "\u001b[1m\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "\u001b[36m\u001b[1mTO AVOID THIS WAIT MIGRATE THE SCRIPT\u001b[m\n",
            "Continuing in 60 seconds (press Ctrl-C to abort) ...\n",
            "\n",
            "\n",
            "## Installing the NodeSource Node.js 16.x repo...\n",
            "\n",
            "\n",
            "## Populating apt-get cache...\n",
            "\n",
            "+ apt-get update\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [517 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,144 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [44.0 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,016 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,287 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,264 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,165 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Hit:18 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:19 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,197 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,128 kB]\n",
            "Get:21 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [37.7 kB]\n",
            "Fetched 10.2 MB in 4s (2,310 kB/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Confirming \"jammy\" is supported...\n",
            "\n",
            "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/jammy/Release'\n",
            "\n",
            "## Adding the NodeSource signing key to your keyring...\n",
            "\n",
            "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
            "\n",
            "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
            "\n",
            "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' > /etc/apt/sources.list.d/nodesource.list\n",
            "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x jammy main' >> /etc/apt/sources.list.d/nodesource.list\n",
            "\n",
            "## Running `apt-get update` for you...\n",
            "\n",
            "+ apt-get update\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 https://deb.nodesource.com/node_16.x jammy InRelease [4,583 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Get:7 https://deb.nodesource.com/node_16.x jammy/main amd64 Packages [776 B]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,359 B in 2s (3,315 B/s)\n",
            "Reading package lists... Done\n",
            "\n",
            "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
            "## You may also need development tools to build native addons:\n",
            "     sudo apt-get install gcc g++ make\n",
            "## To install the Yarn package manager, run:\n",
            "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
            "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
            "     sudo apt-get update && sudo apt-get install yarn\n",
            "\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 27.2 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x jammy/main amd64 nodejs amd64 16.20.2-deb-1nodesource1 [27.2 MB]\n",
            "Fetched 27.2 MB in 0s (62.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 120895 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.2-deb-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.2-deb-1nodesource1) ...\n",
            "Setting up nodejs (16.20.2-deb-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
            "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-o8s4ajmr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-o8s4ajmr\n",
            "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (2.14.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.33.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from PySvelte==1.0.0) (1.5.3)\n",
            "Collecting typeguard~=2.0 (from PySvelte==1.0.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (0.17.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->PySvelte==1.0.0) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->PySvelte==1.0.0) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (4.8.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->PySvelte==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->PySvelte==1.0.0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->PySvelte==1.0.0) (0.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->PySvelte==1.0.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->PySvelte==1.0.0) (1.3.0)\n",
            "Building wheels for collected packages: PySvelte\n",
            "  Building wheel for PySvelte (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySvelte: filename=PySvelte-1.0.0-py3-none-any.whl size=158305 sha256=29b28fa8701414d7c9e2a79b53fd1febfa8cf53b738cbef105ed38ca98468f1a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-olzvt9jb/wheels/fa/f6/f2/673ef7aeb78d7503b6e3e42387132822fdc38d3ee283d3e5b4\n",
            "Successfully built PySvelte\n",
            "Installing collected packages: typeguard, PySvelte\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.1.5\n",
            "    Uninstalling typeguard-4.1.5:\n",
            "      Successfully uninstalled typeguard-4.1.5\n",
            "Successfully installed PySvelte-1.0.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "DEBUG_MODE = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    %pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
        "    # Install another version of node that makes PySvelte work way faster\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKoTs7VBIAiD"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "\n",
        "if IN_COLAB or not DEBUG_MODE:\n",
        "    # Thanks to annoying rendering issues, Plotly graphics will either show up in colab OR Vscode depending on the renderer - this is bad for developing demos! Thus creating a debug mode.\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6b1n2tvIAiD"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.notebook as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from jaxtyping import Float, Int\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuhzYxbsIAiE"
      },
      "outputs": [],
      "source": [
        "import pysvelte\n",
        "\n",
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hccba0v-IAiF"
      },
      "source": [
        "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFMTUcQiIAiF",
        "outputId": "d8756867-7d40-4228-f44c-5ad7dec1958c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7bce0ac4e620>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyKb4C51IAiG"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFs9BrbzIAiH"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, **kwargs):\n",
        "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "OLkInsdjyHMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decide which model to use (eg. gpt2-small vs -medium)"
      ],
      "metadata": {
        "id": "ssJgoKr2yI8O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLwDyosvIAiJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b3eb7fd53f384a2587ea7755da289253",
            "0538ce40cd684b939f83a2f8b5e3993e",
            "20c3023552b746a8af3ad81987dade56",
            "b4af7a24c17a4d83b9e4ef2c01a8abf1",
            "0781de95c7f64eb18dfa48dbea8b600e",
            "9ed40fd95fdf4f878f312329ddde61f4",
            "7d0532f90f9f4860860008fa7036aa6b",
            "a3996e397a3d489ba3e53e0d4f593c5f",
            "14fbcc771517435893d7749cad4791ae",
            "39607a5cc2104064bfd6b19600b1dd50",
            "4aa1d5b0a6e34bfaa5dd9a7e6467ed64",
            "252993fdf40c4255a0ca90987bbfa160",
            "477dfa9f147744e28d877524cf69c3db",
            "a6dddadc99894d42ad6f28a96e0af143",
            "765260d6b3c84d559120afbcd3a231f8",
            "2c5bd7832a1f442f873dc699197b472c",
            "1982310a15b44f2a8cb19a55e5eec543",
            "cd4d16cdfa67428e8444af865b385c43",
            "51ca627f7c4d49a6b7d151044647002f",
            "027d093e5aae46f3ac3b7c0c127ec260",
            "28c083bf4fbb47dbb0698ff9ded0dfe5",
            "ebfd226f086547e6b0acaf5609a63b48",
            "264f3f5ce88a49599344839005a2dc15",
            "5873c9d894194d95b05d424380f5589f",
            "4238a5d20ea74ba7b99e7311c5471ffe",
            "290d252476224cd8bc8ad93696f5e275",
            "cc2cc3718c8e45a9bc90d9216990f2df",
            "d8666f8fbc3748b99000bd36e9e72af8",
            "d4afc56257de4eb381e44be627152675",
            "e91590bc144243e08110fb0f9a04b991",
            "1b86d7793eda415fbcbde60ade461895",
            "0ab9232c1675462f97e91d46a243b344",
            "3d4b184f84bc40bbab894e1fbd4020f1",
            "13a8de3dd0af46048559590cabfe7e2b",
            "f4a84f43ed564415a5fffc2335598050",
            "95bc1345418946d2899e12d04d49ebee",
            "b3687fc275c14e998124758a0a273dd9",
            "a0678325b2844d61b63dfe0cbe15b9b5",
            "aeb503a0cd964b2997c4b7c3fe337629",
            "04aa2678d05841018473814a74d39f16",
            "5d4048c18906493c9cacefbd99489dee",
            "30df5cb87b34488fba9d720327ee73d1",
            "a11a28b9c821482abfa9b96a8694946e",
            "90cab21801db4305a275d4ebe50fca7c",
            "405a54edf77248efae0c7e8cea7dfca5",
            "ab5c8a7ebc1e4cad8f7aa2ebef791bcd",
            "e3c152a1f19e4094abc1e8f5d1458c5f",
            "f2d14c98825c4613a2aa932e7b0036b4",
            "5de38ea9f6c240f7a1179da0a7b2c7fe",
            "dfefc14764c74e64b3461ccbd7801dde",
            "daf940fabcdb4651bc65e11760edf426",
            "2387707564ed41f3b42a2d3bfaa0baf6",
            "32ad23adcf414df08d69729367d33558",
            "9188cb599b9948c2a88703f36f2c9e51",
            "63bfc571db7043febd8a83536b68fd1f",
            "a200035bed704d3f8ff74be5f019ce88",
            "1abd8257caf84aefb9414dfb829d835a",
            "f13483f3dd4d49ba87041efa3c53c46c",
            "318b8032ca394b0fb41ff8fe7f43de97",
            "75b3e5b0dcac4eda97037aa9fc822924",
            "211356e903ab4f85b03baacffc8549dd",
            "a631271f51b844c89ba8382be197ebea",
            "4c17ec1ecc214f34b6f82b06db57f004",
            "819e1bccf39a458a8fce7e3225748171",
            "27f3a407e6e647eb821294f00ccdaf9a",
            "ffbfec6608834bd587cd0dfa961e06f7"
          ]
        },
        "outputId": "6da8cad6-3a8a-4e73-d609-046eb1da91e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3eb7fd53f384a2587ea7755da289253"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "252993fdf40c4255a0ca90987bbfa160"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "264f3f5ce88a49599344839005a2dc15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13a8de3dd0af46048559590cabfe7e2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "405a54edf77248efae0c7e8cea7dfca5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a200035bed704d3f8ff74be5f019ce88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using pad_token, but it is not set yet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "model = HookedTransformer.from_pretrained(\n",
        "    \"gpt2-small\",\n",
        "    center_unembed=True,\n",
        "    center_writing_weights=True,\n",
        "    fold_ln=True,\n",
        "    refactor_factored_attn_matrices=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import functions from repo"
      ],
      "metadata": {
        "id": "Z4iJEGh6b56v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/callummcdougall/ARENA_2.0.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdh5--MfYw7-",
        "outputId": "ede75e60-4e97-4257-acb5-ee0683532005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ARENA_2.0'...\n",
            "remote: Enumerating objects: 9006, done.\u001b[K\n",
            "remote: Counting objects: 100% (9006/9006), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3497/3497), done.\u001b[K\n",
            "remote: Total 9006 (delta 5468), reused 8860 (delta 5412), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (9006/9006), 155.22 MiB | 36.71 MiB/s, done.\n",
            "Resolving deltas: 100% (5468/5468), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZ4C_bsXZFfj",
        "outputId": "f7fb6009-6af6-4852-eef9-2288b96e18de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ARENA_2.0/chapter1_transformers/exercises/part3_indirect_object_identification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ioi_circuit_extraction as ioi_circuit_extraction"
      ],
      "metadata": {
        "id": "OT0Sn571ZnkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate dataset with multiple prompts"
      ],
      "metadata": {
        "id": "cGX9iHAz_UKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "    def __init__(self, prompts, tokenizer, S1_is_first=False):\n",
        "        self.prompts = prompts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.N = len(prompts)\n",
        "        self.max_len = max(\n",
        "            [\n",
        "                len(self.tokenizer(prompt[\"text\"]).input_ids)\n",
        "                for prompt in self.prompts\n",
        "            ]\n",
        "        )\n",
        "        # all_ids = [prompt[\"TEMPLATE_IDX\"] for prompt in self.ioi_prompts]\n",
        "        all_ids = [0 for prompt in self.prompts] # only 1 template\n",
        "        all_ids_ar = np.array(all_ids)\n",
        "        self.groups = []\n",
        "        for id in list(set(all_ids)):\n",
        "            self.groups.append(np.where(all_ids_ar == id)[0])\n",
        "\n",
        "        texts = [ prompt[\"text\"] for prompt in self.prompts ]\n",
        "        self.toks = torch.Tensor(self.tokenizer(texts, padding=True).input_ids).type(\n",
        "            torch.int\n",
        "        )\n",
        "        self.io_tokenIDs = [\n",
        "            self.tokenizer.encode(\" \" + prompt[\"S5\"])[0] for prompt in self.prompts\n",
        "        ]\n",
        "        self.s_tokenIDs = [\n",
        "            self.tokenizer.encode(\" \" + prompt[\"S4\"])[0] for prompt in self.prompts\n",
        "        ]\n",
        "\n",
        "        # word_idx: for every prompt, find the token index of each target token and \"end\"\n",
        "        # word_idx is a tensor with an element for each prompt. The element is the targ token's ind at that prompt\n",
        "        self.word_idx = {}\n",
        "        for targ in [key for key in self.prompts[0].keys() if (key != 'text' and key != 'S5')]:\n",
        "            targ_lst = []\n",
        "            for prompt in self.prompts:\n",
        "                input_text = prompt[\"text\"]\n",
        "                tokens = model.tokenizer.tokenize(input_text)\n",
        "                if S1_is_first and targ == \"S1\":  # only use this if first token doesn't have space Ġ in front\n",
        "                    target_token = prompt[targ]\n",
        "                else:\n",
        "                    target_token = \"Ġ\" + prompt[targ]\n",
        "                target_index = tokens.index(target_token)\n",
        "                targ_lst.append(target_index)\n",
        "            self.word_idx[targ] = torch.tensor(targ_lst)\n",
        "\n",
        "        targ_lst = []\n",
        "        for prompt in self.prompts:\n",
        "            input_text = prompt[\"text\"]\n",
        "            tokens = self.tokenizer.tokenize(input_text)\n",
        "            end_token_index = len(tokens) - 1\n",
        "            targ_lst.append(end_token_index)\n",
        "        self.word_idx[\"end\"] = torch.tensor(targ_lst)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N"
      ],
      "metadata": {
        "id": "4wXBNWj5FwVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repalce io_tokens with correct answer (next, which is '5') and s_tokens with incorrect (current, which repeats)"
      ],
      "metadata": {
        "id": "exuTCQ_XmmFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompts_list(x ,y):\n",
        "    prompts_list = []\n",
        "    for i in range(x, y):\n",
        "        prompt_dict = {\n",
        "            'S1': str(i),\n",
        "            'S2': str(i+1),\n",
        "            'S3': str(i+2),\n",
        "            'S4': str(i+3),\n",
        "            'S5': str(i+4),\n",
        "            'text': f\"{i} {i+1} {i+2} {i+3}\"\n",
        "        }\n",
        "        prompts_list.append(prompt_dict)\n",
        "    return prompts_list\n",
        "\n",
        "prompts_list = generate_prompts_list(1, 11)"
      ],
      "metadata": {
        "id": "u0NPSKcZ1iDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# template = \"[S1] [S2] [S3] [S4]\"\n",
        "# prompts_list = [{'S1': '1', 'S2': '2', 'S3': '3', 'S4': '4', 'S5': '5', 'text': '1 2 3 4'}]\n",
        "\n",
        "dataset = Dataset(prompts_list, model.tokenizer, S1_is_first=True)"
      ],
      "metadata": {
        "id": "b8HJww_CPuzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompts_list_corr(x ,y):\n",
        "    prompts_list = []\n",
        "    for i in range(x, y):\n",
        "        prompt_dict = {\n",
        "            'S1': str(i),\n",
        "            'S2': str(i+1),\n",
        "            'S3': str(i+2),\n",
        "            'S4': str(i+2),\n",
        "            'S5': str(i+3),\n",
        "            'text': f\"{i} {i+1} {i+2} {i+2}\"\n",
        "        }\n",
        "        prompts_list.append(prompt_dict)\n",
        "    return prompts_list\n",
        "\n",
        "prompts_list_2 = generate_prompts_list_corr(1, 11)"
      ],
      "metadata": {
        "id": "dzzLlCqZS_wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# template = \"[S1] [S2] [S3] [S4]\"\n",
        "# prompts_list = [{'S1': '1', 'S2': '1', 'S3': '1', 'S4': '1', 'S5': '1', 'text': '1 1 1 1'}]\n",
        "\n",
        "dataset_2 = Dataset(prompts_list_2, model.tokenizer, S1_is_first=True)"
      ],
      "metadata": {
        "id": "qkUJQaxhktgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from ioi_dataset import NAMES, IOIDataset\n",
        "\n",
        "# N = 25\n",
        "# ioi_dataset = IOIDataset(\n",
        "#     prompt_type=\"mixed\",\n",
        "#     N=N,\n",
        "#     tokenizer=model.tokenizer,\n",
        "#     prepend_bos=False,\n",
        "#     seed=1,\n",
        "#     # device=str(device)\n",
        "# )\n",
        "# abc_dataset = ioi_dataset.gen_flipped_prompts(\"ABB->XYZ, BAB->XYZ\")"
      ],
      "metadata": {
        "id": "ZtraLbzkaxeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablate the model and compare with original"
      ],
      "metadata": {
        "id": "Lk3bffnCYq-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric"
      ],
      "metadata": {
        "id": "GCCCoO0V7L7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "\n",
        "def logits_to_ave_logit_diff_2(logits: Float[Tensor, \"batch seq d_vocab\"], dataset: Dataset, per_prompt=False):\n",
        "    '''\n",
        "    Returns logit difference between the correct and incorrect answer.\n",
        "\n",
        "    If per_prompt=True, return the array of differences rather than the average.\n",
        "    '''\n",
        "\n",
        "    # Only the final logits are relevant for the answer\n",
        "    # Get the logits corresponding to the indirect object / subject tokens respectively\n",
        "    io_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.io_tokenIDs]\n",
        "    s_logits: Float[Tensor, \"batch\"] = logits[range(logits.size(0)), dataset.word_idx[\"end\"], dataset.s_tokenIDs]\n",
        "    # Find logit difference\n",
        "    answer_logit_diff = io_logits - s_logits\n",
        "    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"
      ],
      "metadata": {
        "id": "CgD41x5nbKKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with every head intact (sanity check)"
      ],
      "metadata": {
        "id": "t3lt-2sGzEDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(sanity check to ensure ablation and means_dataset done right)"
      ],
      "metadata": {
        "id": "8xu2lIPZzJhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [(x, y) for x in range(12) for y in range(12)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": pairs,\n",
        "    \"number mover 4\": pairs,\n",
        "    \"number mover 3\": pairs,\n",
        "    \"number mover 2\": pairs,\n",
        "    \"number mover 1\": pairs,\n",
        "    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n",
        "    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n",
        "    # \"negative name mover\": [(10, 7), (11, 10)],\n",
        "    # \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
        "    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
        "    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n",
        "    # \"previous token\": [(2, 2), (4, 11)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "    # \"name mover\": \"end\",\n",
        "    # \"backup name mover\": \"end\",\n",
        "    # \"negative name mover\": \"end\",\n",
        "    # \"s2 inhibition\": \"end\",\n",
        "    # \"induction\": \"S2\",\n",
        "    # \"duplicate token\": \"S2\",\n",
        "    # \"previous token\": \"S1+1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eueJ_s5zJy8",
        "outputId": "d6c295c8-5b08-4de7-b1d4-d01bf06e9113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 4.6238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is good; we used the same dataset, but just its mean, and we get close logits after telling the function to keep every head"
      ],
      "metadata": {
        "id": "6JXkaMakznSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with original name mover circuit (sanity check)"
      ],
      "metadata": {
        "id": "inzYVq8extsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CIRCUIT = {\n",
        "    # \"number mover\": [(9, 1)],\n",
        "    \"name mover\": [(9, 9), (10, 0), (9, 6)],\n",
        "    \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n",
        "    \"negative name mover\": [(10, 7), (11, 10)],\n",
        "    \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
        "    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
        "    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n",
        "    # \"previous token\": [(2, 2), (4, 11)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    # \"number mover\": \"end\",\n",
        "    \"name mover\": \"end\",\n",
        "    \"backup name mover\": \"end\",\n",
        "    \"negative name mover\": \"end\",\n",
        "    \"s2 inhibition\": \"end\",\n",
        "    # \"induction\": \"S2\",\n",
        "    # \"duplicate token\": \"S2\",\n",
        "    # \"previous token\": \"S1+1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63d4644-e328-4590-80e0-50963d7a672c",
        "id": "NqmhOd9lxtsg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): -0.5582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good; as expected, it should be low, as that circuit has nothing to do with ours. This ensures we're not just getting high scores for anything."
      ],
      "metadata": {
        "id": "E6qLQEUz242B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with only one head"
      ],
      "metadata": {
        "id": "F-LT4lCSxhe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CIRCUIT = {\n",
        "    \"number mover\": [(9, 1)],\n",
        "    \"number mover 4\": [(9, 1)],\n",
        "    \"number mover 3\": [(9, 1)],\n",
        "    \"number mover 2\": [(9, 1)],\n",
        "    \"number mover 1\": [(9, 1)],\n",
        "    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n",
        "    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n",
        "    # \"negative name mover\": [(10, 7), (11, 10)],\n",
        "    # \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
        "    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
        "    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n",
        "    # \"previous token\": [(2, 2), (4, 11)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "    # \"name mover\": \"end\",\n",
        "    # \"backup name mover\": \"end\",\n",
        "    # \"negative name mover\": \"end\",\n",
        "    # \"s2 inhibition\": \"end\",\n",
        "    # \"induction\": \"S2\",\n",
        "    # \"duplicate token\": \"S2\",\n",
        "    # \"previous token\": \"S1+1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "id": "xEeHN5WHGVad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679d2d51-5c6c-487d-e10a-23538893d9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): -0.1450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L0 to L9"
      ],
      "metadata": {
        "id": "caokBrDh0LVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [(x, y) for x in range(10) for y in range(10)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": pairs,\n",
        "    \"number mover 4\": pairs,\n",
        "    \"number mover 3\": pairs,\n",
        "    \"number mover 2\": pairs,\n",
        "    \"number mover 1\": pairs,\n",
        "    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n",
        "    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n",
        "    # \"negative name mover\": [(10, 7), (11, 10)],\n",
        "    # \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
        "    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
        "    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n",
        "    # \"previous token\": [(2, 2), (4, 11)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "    # \"name mover\": \"end\",\n",
        "    # \"backup name mover\": \"end\",\n",
        "    # \"negative name mover\": \"end\",\n",
        "    # \"s2 inhibition\": \"end\",\n",
        "    # \"induction\": \"S2\",\n",
        "    # \"duplicate token\": \"S2\",\n",
        "    # \"previous token\": \"S1+1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmIIrX0S0OOS",
        "outputId": "cf9b9c66-24be-4525-dcfe-19c24a4b1d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.9240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shouldn't the heads be from 0 to 12?"
      ],
      "metadata": {
        "id": "a4QJDpmcY_NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [(x, y) for x in range(10) for y in range(12)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": pairs,\n",
        "    \"number mover 4\": pairs,\n",
        "    \"number mover 3\": pairs,\n",
        "    \"number mover 2\": pairs,\n",
        "    \"number mover 1\": pairs,\n",
        "    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n",
        "    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n",
        "    # \"negative name mover\": [(10, 7), (11, 10)],\n",
        "    # \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
        "    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
        "    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n",
        "    # \"previous token\": [(2, 2), (4, 11)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "    # \"name mover\": \"end\",\n",
        "    # \"backup name mover\": \"end\",\n",
        "    # \"negative name mover\": \"end\",\n",
        "    # \"s2 inhibition\": \"end\",\n",
        "    # \"induction\": \"S2\",\n",
        "    # \"duplicate token\": \"S2\",\n",
        "    # \"previous token\": \"S1+1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy4g6VO6Y97C",
        "outputId": "0c04f903-95c6-41d6-9599-876185267c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 4.0961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FOUND ERROR- before, we only generated heads from 0 to 9 for layers 0 to 9 (using range(10)). But to get rid of layers 10 and 11 means we still need heads 0 to 11 for L0 to L9. So when we do that, “L0 to L9” gets 4/4.6 performance!"
      ],
      "metadata": {
        "id": "vCQXpmBc_yez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is that nearly full performance? Try y from 0 to 11"
      ],
      "metadata": {
        "id": "JPxyeF2kZUFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [(x, y) for x in range(10) for y in range(11)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": pairs,\n",
        "    \"number mover 4\": pairs,\n",
        "    \"number mover 3\": pairs,\n",
        "    \"number mover 2\": pairs,\n",
        "    \"number mover 1\": pairs,\n",
        "    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n",
        "    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n",
        "    # \"negative name mover\": [(10, 7), (11, 10)],\n",
        "    # \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
        "    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
        "    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n",
        "    # \"previous token\": [(2, 2), (4, 11)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "    # \"name mover\": \"end\",\n",
        "    # \"backup name mover\": \"end\",\n",
        "    # \"negative name mover\": \"end\",\n",
        "    # \"s2 inhibition\": \"end\",\n",
        "    # \"induction\": \"S2\",\n",
        "    # \"duplicate token\": \"S2\",\n",
        "    # \"previous token\": \"S1+1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VmJ7eiNZXAn",
        "outputId": "3fad6e09-0377-4573-f7db-58cc9399d23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.9595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## L0 to L8"
      ],
      "metadata": {
        "id": "DL41vZDz7jfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok now all heads, but skip layer 9. This means 9.1 won't be there."
      ],
      "metadata": {
        "id": "-tCykoEGZdyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB-2v37HZkBm",
        "outputId": "1e7738f1-bd79-4697-b24e-a463d26b8f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [(x, y) for x in range(9) for y in range(12)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": pairs,\n",
        "    \"number mover 4\": pairs,\n",
        "    \"number mover 3\": pairs,\n",
        "    \"number mover 2\": pairs,\n",
        "    \"number mover 1\": pairs,\n",
        "    # \"name mover\": [(9, 9), (10, 0), (9, 6)],\n",
        "    # \"backup name mover\": [(10, 10), (10, 6), (10, 2), (10, 1), (11, 2), (9, 7), (9, 0), (11, 9)],\n",
        "    # \"negative name mover\": [(10, 7), (11, 10)],\n",
        "    # \"s2 inhibition\": [(7, 3), (7, 9), (8, 6), (8, 10)],\n",
        "    # \"induction\": [(5, 5), (5, 8), (5, 9), (6, 9)],\n",
        "    # \"duplicate token\": [(0, 1), (0, 10), (3, 0)],\n",
        "    # \"previous token\": [(2, 2), (4, 11)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "    # \"name mover\": \"end\",\n",
        "    # \"backup name mover\": \"end\",\n",
        "    # \"negative name mover\": \"end\",\n",
        "    # \"s2 inhibition\": \"end\",\n",
        "    # \"induction\": \"S2\",\n",
        "    # \"duplicate token\": \"S2\",\n",
        "    # \"previous token\": \"S1+1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_9RCPYKZhuQ",
        "outputId": "f780a3b7-d588-4b8c-e890-86e03301328a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.9032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now ”L0 to “L8” only gets 2.9/4.6 performance. So the most impt heads are NOT in L10 and L11, but in L9 or before. We should search for them there.\n",
        "\n",
        "Though 0.6/4.6 is still pretty big, so later search for the L10 and L11 heads for that 0.6 perf."
      ],
      "metadata": {
        "id": "Eul__hSo_0Sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test with top 10 heads from actv patching"
      ],
      "metadata": {
        "id": "iCQ7UnXjx9tX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10, regardless of pos or neg"
      ],
      "metadata": {
        "id": "OI5_l8Wyl68v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CIRCUIT = {\n",
        "    \"number mover\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7)],\n",
        "    \"number mover 4\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7)],\n",
        "    \"number mover 3\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7)],\n",
        "    \"number mover 2\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7)],\n",
        "    \"number mover 1\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccf7b6c7-219f-49eb-e56f-4db75d0f2dad",
        "id": "QaG-6qOwx9tY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 0.8705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### the top 10 positive"
      ],
      "metadata": {
        "id": "tQ0KbjmJ7TvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heads = [(9, 1), (7, 10), (10, 7), (8, 8), (0, 1), (8, 11), (6, 1), (0, 5), (9, 9), (11, 10)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": heads,\n",
        "    \"number mover 4\": heads,\n",
        "    \"number mover 3\": heads,\n",
        "    \"number mover 2\": heads,\n",
        "    \"number mover 1\": heads,\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "}\n",
        "\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAfC_Ofj7SeH",
        "outputId": "6b79c586-7714-4f42-d841-cd7eaa90baec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): -0.2478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test heads from path patching"
      ],
      "metadata": {
        "id": "B4caIj8kV7yN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CIRCUIT = {\n",
        "    \"number mover\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7), (4,4), (6,6), (3,0)],\n",
        "    \"number mover 4\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7), (4,4), (6,6), (3,0)],\n",
        "    \"number mover 3\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7), (4,4), (6,6), (3,0)],\n",
        "    \"number mover 2\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7), (4,4), (6,6), (3,0)],\n",
        "    \"number mover 1\": [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7), (4,4), (6,6), (3,0)],\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adacc632-39e4-4919-fab5-32d8256fe44b",
        "id": "O2kfhry2V7yk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.8915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test heads from path patching plus all L10, L11 heads"
      ],
      "metadata": {
        "id": "abgjQqcTYIoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given list\n",
        "lst = [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (10,7), (4,4), (6,6), (3,0)]\n",
        "\n",
        "# Add tuples (10, i) and (11, i) for i from 0 to 11\n",
        "lst.extend((10, i) for i in range(12))\n",
        "lst.extend((11, i) for i in range(12))\n",
        "\n",
        "print(lst)\n",
        "\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": lst,\n",
        "    \"number mover 4\": lst,\n",
        "    \"number mover 3\": lst,\n",
        "    \"number mover 2\": lst,\n",
        "    \"number mover 1\": lst,\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0730e9-0270-4409-c834-71fa3f3e88b3",
        "id": "m-VMaeR8YIo5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 10), (0, 1), (5, 5), (6, 1), (7, 10), (8, 8), (7, 11), (8, 11), (9, 1), (9, 5), (10, 7), (4, 4), (6, 6), (3, 0), (10, 0), (10, 1), (10, 2), (10, 3), (10, 4), (10, 5), (10, 6), (10, 7), (10, 8), (10, 9), (10, 10), (10, 11), (11, 0), (11, 1), (11, 2), (11, 3), (11, 4), (11, 5), (11, 6), (11, 7), (11, 8), (11, 9), (11, 10), (11, 11)]\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.8225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is only 1.8225. This DECREASES perf. Perhaps there are ‘negative’ actv heads in L10 and L11 for the corr tokens which will not be “countered’ (shut off) by the right heads that are missing."
      ],
      "metadata": {
        "id": "XOStJdBQ_lA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test heads from path patching minus any L10, L11 heads"
      ],
      "metadata": {
        "id": "mUzOXMnd9TsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Given list\n",
        "lst = [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (4,4), (6,6), (3,0)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": lst,\n",
        "    \"number mover 4\": lst,\n",
        "    \"number mover 3\": lst,\n",
        "    \"number mover 2\": lst,\n",
        "    \"number mover 1\": lst,\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26ecd00-5552-4daf-c3a7-0be864338f80",
        "id": "lSd5bGLP9TsW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.4739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gets rid of only 10.7, but decreases from 1.89 to 1.4. So 10.7 is still impt."
      ],
      "metadata": {
        "id": "9nHvklVz_jdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add in all heads from one layer, try L0 to L9"
      ],
      "metadata": {
        "id": "770eDeeW9y8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This has iterations where in each iter, all the heads from a layer are added to our “best heads list” so far"
      ],
      "metadata": {
        "id": "4z7OHDcy_byE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in range(0,9):\n",
        "    lst = [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (4,4), (6,6), (3,0), (10,7)]\n",
        "\n",
        "    lst.extend((layer, i) for i in range(12))\n",
        "\n",
        "    CIRCUIT = {\n",
        "        \"number mover\": lst,\n",
        "        \"number mover 4\": lst,\n",
        "        \"number mover 3\": lst,\n",
        "        \"number mover 2\": lst,\n",
        "        \"number mover 1\": lst,\n",
        "    }\n",
        "\n",
        "    SEQ_POS_TO_KEEP = {\n",
        "        \"number mover\": \"end\",\n",
        "        \"number mover 4\": \"S4\",\n",
        "        \"number mover 3\": \"S3\",\n",
        "        \"number mover 2\": \"S2\",\n",
        "        \"number mover 1\": \"S1\",\n",
        "    }\n",
        "\n",
        "    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "    ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "    print(\"Added in all heads from layer \" + str(layer))\n",
        "    print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "    print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b03e342-e9db-46ab-dc98-cae8c1c9be44",
        "id": "zFJV0dmS9y8s"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added in all heads from layer 0\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.6466\n",
            "\n",
            "\n",
            "Added in all heads from layer 1\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.8406\n",
            "\n",
            "\n",
            "Added in all heads from layer 2\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.1621\n",
            "\n",
            "\n",
            "Added in all heads from layer 3\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.2274\n",
            "\n",
            "\n",
            "Added in all heads from layer 4\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.2291\n",
            "\n",
            "\n",
            "Added in all heads from layer 5\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.3852\n",
            "\n",
            "\n",
            "Added in all heads from layer 6\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.9680\n",
            "\n",
            "\n",
            "Added in all heads from layer 7\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.0691\n",
            "\n",
            "\n",
            "Added in all heads from layer 8\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.0894\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All layers except L5 increase from 1.89."
      ],
      "metadata": {
        "id": "NdA6WO10_eKP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add in all heads from all prev layers, try L0 to L9"
      ],
      "metadata": {
        "id": "F769zA07_XpM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like before, but at each iteration, add in all heads from that layer iteration and all layers before it. We are testing if there is a “combination” needed, not just a full layer."
      ],
      "metadata": {
        "id": "HvdXb7Y7_asO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in range(0,9):\n",
        "    lst = [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (4,4), (6,6), (3,0), (10,7)]\n",
        "\n",
        "    for prev_layer in range(0, layer+1):\n",
        "        lst.extend((prev_layer, i) for i in range(12))\n",
        "\n",
        "    CIRCUIT = {\n",
        "        \"number mover\": lst,\n",
        "        \"number mover 4\": lst,\n",
        "        \"number mover 3\": lst,\n",
        "        \"number mover 2\": lst,\n",
        "        \"number mover 1\": lst,\n",
        "    }\n",
        "\n",
        "    SEQ_POS_TO_KEEP = {\n",
        "        \"number mover\": \"end\",\n",
        "        \"number mover 4\": \"S4\",\n",
        "        \"number mover 3\": \"S3\",\n",
        "        \"number mover 2\": \"S2\",\n",
        "        \"number mover 1\": \"S1\",\n",
        "    }\n",
        "\n",
        "    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "    ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "    print(\"Added in all heads from layer \" + str(layer))\n",
        "    print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "    print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830ade46-1d79-46f1-8810-1ffa0b65f06c",
        "id": "ZHyyl_9e_XpW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added in all heads from layer 0\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.6466\n",
            "\n",
            "\n",
            "Added in all heads from layer 1\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 3.2385\n",
            "\n",
            "\n",
            "Added in all heads from layer 2\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 3.4123\n",
            "\n",
            "\n",
            "Added in all heads from layer 3\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 3.4748\n",
            "\n",
            "\n",
            "Added in all heads from layer 4\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 3.6169\n",
            "\n",
            "\n",
            "Added in all heads from layer 5\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 3.9388\n",
            "\n",
            "\n",
            "Added in all heads from layer 6\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 4.0548\n",
            "\n",
            "\n",
            "Added in all heads from layer 7\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 4.3153\n",
            "\n",
            "\n",
            "Added in all heads from layer 8\n",
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 4.6538\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now each new layer has a bigger increase. By L8, we have all the heads we need to get full performance. This means we should confine our search to L0 to L8."
      ],
      "metadata": {
        "id": "vSugIqW5C2_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is this an error? 4.6538 is HIGHER than the entire model. Does that mean L10 and L11 heads were holding it back? Clearly, L0 to L8 only had a score of 2.9, so other heads were needed. But is this an error in our mean ablation approach, or were other L9 to L11 heads making perf worse for this task (though not for all tasks in general, as there's a tradeoff when the model needs to handle multiple prediction tasks?)\n",
        "\n",
        "Notice that when we remove completely the layers 10 and 11 (in the extract model expms), not just mean ablate, we also get better results ?"
      ],
      "metadata": {
        "id": "EEBtpcQ4DL9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add in other heads from path patching"
      ],
      "metadata": {
        "id": "Ix90oYfZEqMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get heads from heatmaps of:\n",
        "\n",
        "https://colab.research.google.com/drive/1UQZrumDk5gEWuIlb4nZWRms8gbFf4z-w#scrollTo=teSb1k5Ul6mS"
      ],
      "metadata": {
        "id": "AUuBIosOEqMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [(0, 10), (0, 1), (5,5), (6,1), (7, 10), (8,8), (7,11), (8,11), (9,1), (9,5), (4,4), (6,6), (3,0), (10,7)]\n",
        "lst = sorted(data, key=lambda x: (x[0], x[1]))\n",
        "print(lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "batgvahlFhHX",
        "outputId": "e317635d-9f93-4d66-80d1-d30e69c1f9c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,5), (1,5), (0,10), (6,9)]\n",
        "\n",
        "CIRCUIT = {\n",
        "    \"number mover\": lst,\n",
        "    \"number mover 4\": lst,\n",
        "    \"number mover 3\": lst,\n",
        "    \"number mover 2\": lst,\n",
        "    \"number mover 1\": lst,\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "}\n",
        "\n",
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0109a806-44bd-4c4a-c63f-a646a7f63610",
        "id": "r6zmkCWBEqMv"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.4724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is worse than adding in all of L0."
      ],
      "metadata": {
        "id": "vaOdMVJOEqMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add in other heads from path patching, L0 only"
      ],
      "metadata": {
        "id": "8293qqJoGlA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to start by adding in L0 node combos, guided by what's found impt from path patching. Try to get to the top L0 score 2.6466 from adding in all heads, using as few heads as possible."
      ],
      "metadata": {
        "id": "nqZBvDX6H5C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7)]\n",
        "\n",
        "def mean_ablate_by_lst(lst, model):\n",
        "    CIRCUIT = {\n",
        "        \"number mover\": lst,\n",
        "        \"number mover 4\": lst,\n",
        "        \"number mover 3\": lst,\n",
        "        \"number mover 2\": lst,\n",
        "        \"number mover 1\": lst,\n",
        "    }\n",
        "\n",
        "    SEQ_POS_TO_KEEP = {\n",
        "        \"number mover\": \"end\",\n",
        "        \"number mover 4\": \"S4\",\n",
        "        \"number mover 3\": \"S3\",\n",
        "        \"number mover 2\": \"S2\",\n",
        "        \"number mover 1\": \"S1\",\n",
        "    }\n",
        "\n",
        "    model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "    ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "    ioi_logits_minimal = model(dataset.toks)\n",
        "\n",
        "    print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "    print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1c54b8-c46a-46e2-b8c0-514542a8a5e2",
        "id": "VaxbugcfGlBA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.8915\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,5), (0,10)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XYsKKXQG97y",
        "outputId": "b2191f37-08e2-420b-dfc3-dbfa1a894024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 1.9763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sttIbS6uHMYs",
        "outputId": "89345162-98de-4752-844e-60a3e20042ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.0532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF-1cVv8HQkh",
        "outputId": "d0bc6ea9-f6b6-4983-eb70-5ffb3c496dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.0832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4), (0,5)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or_Ppn0qHcRE",
        "outputId": "bddc5d62-54ca-4c48-b7b8-decf648def45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.1826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4), (0,5), (0,6)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc4wLVnFHgj2",
        "outputId": "1ee40ff2-f82c-4d39-acfd-f0fe18f8b332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.1941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4), (0,5), (0,6), (0,7)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn11SKUjHked",
        "outputId": "4eca376b-e1c3-45f7-80ac-a7852c450af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.3127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4), (0,5), (0,6), (0,7), (0,8)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCS2c10hHoKI",
        "outputId": "b79d34c8-adbf-40c7-c1e0-3c2e635211eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.4065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4), (0,5), (0,6), (0,7), (0,8), (0,9)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5jVf_H4Huvm",
        "outputId": "77c195b0-5068-4088-e79d-b24b89b23401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.6471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why is this better than 2.6466?"
      ],
      "metadata": {
        "id": "BGFQbRw2H85r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4), (0,5), (0,6), (0,7), (0,8), (0,9), (0,11)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGrQCADDIBJo",
        "outputId": "b3f1f776-728d-4cc9-e90f-8c97c0419611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.6654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [(0, 1), (0, 10), (3, 0), (4, 4), (5, 5), (6, 1), (6, 6), (7, 10), (7, 11), (8, 8), (8, 11), (9, 1), (9, 5), (10, 7),\n",
        "       (0,2), (0,3), (0,4), (0,5), (0,6), (0,7), (0,8), (0,9), (0,11), (0,0)]\n",
        "\n",
        "mean_ablate_by_lst(lst, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3nlxV0HIFmY",
        "outputId": "7905884e-83aa-45bf-a386-0ffe96073e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average logit difference (IOI dataset, using entire model): 4.6238\n",
            "Average logit difference (IOI dataset, only using circuit): 2.6466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it appears adding in 0.11 and 0.0 DECREASE performance, while all other heads INCREASE performance. Which combo of heads has the biggest contribution? Remember, looking at one head's combo in isolation isn't enough, as that head may have a huge contribution when paired when another head, and this \"emergent\" effect can't be guessed just by looking at adding them separately from one another."
      ],
      "metadata": {
        "id": "CFgaT2DPIJRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our next notebook (pt2), we want to automate this search process by having the script check the score against a threshold. Try backtracking, etc."
      ],
      "metadata": {
        "id": "NqbzB20IIeUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare circuit score with random subgraphs' scores"
      ],
      "metadata": {
        "id": "GhBgkmGp44h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_random_pairs():\n",
        "    pairs = []\n",
        "    for _ in range(12):\n",
        "        x = random.randint(0, 11)\n",
        "        y = random.randint(0, 11)\n",
        "        pairs.append((x, y))\n",
        "    return pairs\n",
        "\n",
        "random_pairs = generate_random_pairs()\n",
        "print(random_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4p7q6Zx47PD",
        "outputId": "5292a157-bdd5-417f-bd4f-38204483cfc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(8, 3), (10, 4), (5, 1), (0, 7), (2, 3), (8, 9), (1, 0), (9, 8), (6, 0), (9, 10), (7, 0), (1, 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CIRCUIT = {\n",
        "    \"number mover\": random_pairs,\n",
        "    \"number mover 4\": random_pairs,\n",
        "    \"number mover 3\": random_pairs,\n",
        "    \"number mover 2\": random_pairs,\n",
        "    \"number mover 1\": random_pairs,\n",
        "}\n",
        "\n",
        "SEQ_POS_TO_KEEP = {\n",
        "    \"number mover\": \"end\",\n",
        "    \"number mover 4\": \"S4\",\n",
        "    \"number mover 3\": \"S3\",\n",
        "    \"number mover 2\": \"S2\",\n",
        "    \"number mover 1\": \"S1\",\n",
        "}"
      ],
      "metadata": {
        "id": "5vZa5q239W2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_hooks(including_permanent=True)  #must do this after running with mean ablation hook\n",
        "\n",
        "ioi_logits_original, ioi_cache = model.run_with_cache(dataset.toks)\n",
        "\n",
        "avg_logit_diffs_rand_ablate = []\n",
        "for i in range(20):\n",
        "    random_pairs = generate_random_pairs()\n",
        "    CIRCUIT = {\"number mover\": random_pairs}\n",
        "    model = ioi_circuit_extraction.add_mean_ablation_hook(model, means_dataset=dataset_2, circuit=CIRCUIT, seq_pos_to_keep=SEQ_POS_TO_KEEP)\n",
        "    ioi_logits_minimal = model(dataset.toks)\n",
        "    avg_logit_diffs_rand_ablate.append(logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset))\n",
        "    # print(f\"Average logit difference (IOI dataset, using entire model): {logits_to_ave_logit_diff_2(ioi_logits_original, dataset):.4f}\")\n",
        "    # print(f\"Average logit difference (IOI dataset, only using circuit): {logits_to_ave_logit_diff_2(ioi_logits_minimal, dataset):.4f}\")"
      ],
      "metadata": {
        "id": "4-qmbi7k9bmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "avg_logit_diffs_rand_ablate = torch.as_tensor(avg_logit_diffs_rand_ablate)\n",
        "plt.hist(avg_logit_diffs_rand_ablate.cpu())\n",
        "plt.ylabel('Counts')\n",
        "plt.xlabel('avg_logit_diffs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "PLdU2yQZ9kKH",
        "outputId": "f7de2b93-7c6d-44fc-c526-526751ee464d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'avg_logit_diffs')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mean = np.mean(avg_logit_diffs_rand_ablate)\n",
        "# variance = np.var(avg_logit_diffs_rand_ablate)\n",
        "mean = torch.mean(avg_logit_diffs_rand_ablate)\n",
        "std_dev = torch.std(avg_logit_diffs_rand_ablate)\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Standard Deviation:\", std_dev.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WgJEgH68HRh",
        "outputId": "c309ff1b-1d78-4aec-a93e-4cd9e64cb2c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor(-0.2024)\n",
            "Standard Deviation: 0.1460614651441574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, as our circuits have much higher scores than this distribution would say is likely, it is unlikely that these circuits are consistently obtaining these scores by random chance. Note that there are 2^(total number of heads) possible choices of node sets, and this does not even count the connections (given by SEQ_POS_TO_KEEP).\n",
        "\n",
        "1/20 -> 5%"
      ],
      "metadata": {
        "id": "ylAuXGUm_vK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot minimality scores"
      ],
      "metadata": {
        "id": "drSwyz5ees6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install circuitsvis"
      ],
      "metadata": {
        "id": "Cmkr5IZ_gG5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that converts into this:"
      ],
      "metadata": {
        "id": "nVOdpmlKnrH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K_FOR_EACH_COMPONENT = {\n",
        "#     (9, 9): set(),\n",
        "#     (10, 0): {(9, 9)},\n",
        "#     (9, 6): {(9, 9), (10, 0)},\n",
        "#     (10, 7): {(11, 10)},\n",
        "#     (11, 10): {(10, 7)},\n",
        "#     (8, 10): {(7, 9), (8, 6), (7, 3)},\n",
        "#     (7, 9): {(8, 10), (8, 6), (7, 3)},\n",
        "#     (8, 6): {(7, 9), (8, 10), (7, 3)},\n",
        "#     (7, 3): {(7, 9), (8, 10), (8, 6)},\n",
        "#     (5, 5): {(5, 9), (6, 9), (5, 8)},\n",
        "#     (5, 9): {(11, 10), (10, 7)},\n",
        "#     (6, 9): {(5, 9), (5, 5), (5, 8)},\n",
        "#     (5, 8): {(11, 10), (10, 7)},\n",
        "#     (0, 1): {(0, 10), (3, 0)},\n",
        "#     (0, 10): {(0, 1), (3, 0)},\n",
        "#     (3, 0): {(0, 1), (0, 10)},\n",
        "#     (4, 11): {(2, 2)},\n",
        "#     (2, 2): {(4, 11)},\n",
        "#     (11, 2): {(9, 9), (10, 0), (9, 6)},\n",
        "#     (10, 6): {(9, 9), (10, 0), (9, 6), (11, 2)},\n",
        "#     (10, 10): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6)},\n",
        "#     (10, 2): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6), (10, 10)},\n",
        "#     (9, 7): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6), (10, 10), (10, 2)},\n",
        "#     (10, 1): {(9, 9), (10, 0), (9, 6), (11, 2), (10, 6), (10, 10), (10, 2), (9, 7)},\n",
        "#     (11, 9): {(9, 9), (10, 0), (9, 6), (9, 0)},\n",
        "#     (9, 0): {(9, 9), (10, 0), (9, 6), (11, 9)},\n",
        "# }"
      ],
      "metadata": {
        "id": "hMYxQOmHfws4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from solutions import *\n",
        "\n",
        "# def get_score(\n",
        "# \tmodel: HookedTransformer,\n",
        "# \tioi_dataset: IOIDataset,\n",
        "# \tabc_dataset: IOIDataset,\n",
        "# \tK: Set[Tuple[int, int]],\n",
        "# \tC: Dict[str, List[Tuple[int, int]]],\n",
        "# ) -> float:\n",
        "# \t'''\n",
        "# \tReturns the value F(C \\ K), where F is the logit diff, C is the\n",
        "# \tcore circuit, and K is the set of circuit components to remove.\n",
        "# \t'''\n",
        "# \tC_excl_K = {k: [head for head in v if head not in K] for k, v in C.items()}\n",
        "# \tmodel = ioi_circuit_extraction.add_mean_ablation_hook(model, abc_dataset, C_excl_K, SEQ_POS_TO_KEEP)\n",
        "# \tlogits = model(ioi_dataset.toks)\n",
        "# \tscore = logits_to_ave_logit_diff_2(logits, ioi_dataset).item()\n",
        "\n",
        "# \treturn score\n",
        "\n",
        "# def get_minimality_score(\n",
        "# \t\tmodel: HookedTransformer,\n",
        "# \t\tioi_dataset: IOIDataset,\n",
        "# \t\tabc_dataset: IOIDataset,\n",
        "# \t\tv: Tuple[int, int],\n",
        "# \t\tK: Set[Tuple[int, int]],\n",
        "# \t\tC: Dict[str, List[Tuple[int, int]]] = CIRCUIT,\n",
        "# \t) -> float:\n",
        "# \t\t'''\n",
        "# \t\tReturns the value | F(C \\ K_union_v) - F(C | K) |, where F is\n",
        "# \t\tthe logit diff, C is the core circuit, K is the set of circuit\n",
        "# \t\tcomponents to remove, and v is a head (not in K).\n",
        "# \t\t'''\n",
        "# \t\tassert v not in K\n",
        "# \t\tK_union_v = K | {v}\n",
        "# \t\tC_excl_K_score = get_score(model, ioi_dataset, abc_dataset, K, C)\n",
        "# \t\tC_excl_Kv_score = get_score(model, ioi_dataset, abc_dataset, K_union_v, C)\n",
        "\n",
        "# \t\treturn abs(C_excl_K_score - C_excl_Kv_score)\n",
        "\n",
        "# def get_all_minimality_scores(\n",
        "# \t\tmodel: HookedTransformer,\n",
        "# \t\tioi_dataset: IOIDataset = ioi_dataset,\n",
        "# \t\tabc_dataset: IOIDataset = abc_dataset,\n",
        "# \t\tk_for_each_component: Dict = K_FOR_EACH_COMPONENT\n",
        "# \t) -> Dict[Tuple[int, int], float]:\n",
        "# \t\t'''\n",
        "# \t\tReturns dict of minimality scores for every head in the model (as\n",
        "# \t\ta fraction of F(M), the logit diff of the full model).\n",
        "\n",
        "# \t\tWarning - this resets all hooks at the end (including permanent).\n",
        "# \t\t'''\n",
        "# \t\t# Get full circuit score F(M), to divide minimality scores by\n",
        "# \t\tmodel.reset_hooks(including_permanent=True)\n",
        "# \t\tlogits = model(ioi_dataset.toks)\n",
        "# \t\tfull_circuit_score = logits_to_ave_logit_diff_2(logits, ioi_dataset).item()\n",
        "\n",
        "# \t\t# Get all minimality scores, using the `get_minimality_score` function\n",
        "# \t\tminimality_scores = {}\n",
        "# \t\tfor v, K in tqdm(k_for_each_component.items()):\n",
        "# \t\t\tscore = get_minimality_score(model, ioi_dataset, abc_dataset, v, K)\n",
        "# \t\t\tminimality_scores[v] = score / full_circuit_score\n",
        "\n",
        "# \t\tmodel.reset_hooks(including_permanent=True)\n",
        "\n",
        "# \t\treturn minimality_scores"
      ],
      "metadata": {
        "id": "xa6ecFe2f69c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# minimality_scores = get_all_minimality_scores(model)"
      ],
      "metadata": {
        "id": "ma193-c7fGLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def plot_minimal_set_results(minimality_scores: Dict[Tuple[int, int], float]):\n",
        "#     '''\n",
        "#     Plots the minimality results, in a way resembling figure 7 in the paper.\n",
        "\n",
        "#     minimality_scores:\n",
        "#         Dict with elements like (9, 9): minimality score for head 9.9 (as described\n",
        "#         in section 4.2 of the paper)\n",
        "#     '''\n",
        "\n",
        "#     CIRCUIT_reversed = {head: k for k, v in CIRCUIT.items() for head in v}\n",
        "#     colors = [CIRCUIT_reversed[head].capitalize() + \" head\" for head in minimality_scores.keys()]\n",
        "#     color_sequence = [px.colors.qualitative.Dark2[i] for i in [0, 1, 2, 5, 3, 6]] + [\"#BAEA84\"]\n",
        "\n",
        "#     bar(\n",
        "#         list(minimality_scores.values()),\n",
        "#         x=list(map(str, minimality_scores.keys())),\n",
        "#         labels={\"x\": \"Attention head\", \"y\": \"Change in logit diff\", \"color\": \"Head type\"},\n",
        "#         color=colors,\n",
        "#         template=\"ggplot2\",\n",
        "#         color_discrete_sequence=color_sequence,\n",
        "#         bargap=0.02,\n",
        "#         yaxis_tickformat=\".0%\",\n",
        "#         legend_title_text=\"\",\n",
        "#         title=\"Plot of minimality scores (as percentages of full model logit diff)\",\n",
        "#         width=800,\n",
        "#         hovermode=\"x unified\"\n",
        "#     )\n",
        "\n",
        "# plot_minimal_set_results(minimality_scores)"
      ],
      "metadata": {
        "id": "uYaFGosUeitY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}